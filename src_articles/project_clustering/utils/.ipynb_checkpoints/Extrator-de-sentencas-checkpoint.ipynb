{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo de extração de sentenças"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções e métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função que retorna a sentenca\n",
    "def get_Sentence(s):\n",
    "    resp = \"\"\n",
    "    for i in range(len(s)):\n",
    "        if(s[i] == '>'):\n",
    "            resp = s[i+1:]\n",
    "            break\n",
    "    resp = resp.strip()\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variáveis e constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diretorios dos datasets\n",
    "caminhos = ['cameras.xml','cells.xml','dvds.xml','laptops.xml','routers.xml']\n",
    "#Diretorios dos arquivos das sentencas\n",
    "save_sentencas = ['sentencas-camera.txt','sentencas-cells.txt','sentencas-dvds.txt','sentencas-laptops.txt','sentencas-routers.txt']\n",
    "#Diretorios dos arquivos de palavras-sentencas\n",
    "save_palavras = ['palavras-camera.txt','palavras-cells.txt','palavras-dvds.txt','palavras-laptops.txt','palavras-routers.txt']\n",
    "#Diretorios dos arquivos de frequencias de palavras\n",
    "save_frequencias = ['frequencias-camera.txt','frequencias-cells.txt','frequencias-dvds.txt','frequencias-laptops.txt','frequencias-routers.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento do algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para cada dominio\n",
    "for i in range(len(caminhos)):\n",
    "#for i in range(1):\n",
    "    sentencas = [] #Variavel que guarda as sentencas do documento\n",
    "    documentos = [] #Variavel que guarda os documentos do dominio\n",
    "    palavras = {} #Variavel que mapeia as sentencas para as palavras\n",
    "    sentenca = \"\"\n",
    "    palavra = \"\"\n",
    "    #Acessando os datasets\n",
    "    arq = open('../datasets/' + caminhos[i],'r')\n",
    "    #Percorrendo as linhas do arquivo\n",
    "    for linha in arq.readlines():\n",
    "        if('<sentence' in linha):\n",
    "            s = linha.replace('</sentence>','')\n",
    "            s = s.split('idSentence=')[1]\n",
    "            s = get_Sentence(s) #Obtendo a sentenca\n",
    "            sentenca = s\n",
    "            sentencas.append(sentenca)\n",
    "        if('<opinion>' in linha):\n",
    "            p = linha.replace('/opinion','opinion')\n",
    "            p = p.replace('<opinion>','')\n",
    "            p = p.split('\"')\n",
    "            palavra = p[1].lower() #Obtendo o opinion (atributo)\n",
    "            tipo = p[-2]\n",
    "            if(tipo != 'anaphora' and (palavra not in set(stopwords.words('english')))):\n",
    "                if(palavra not in palavras.keys()):\n",
    "                    palavras[palavra] = set()\n",
    "                palavras[palavra].add(sentenca)\n",
    "        if('</review>' in linha):\n",
    "            sentenca = \"\"\n",
    "            palavra = \"\"\n",
    "            documentos.append(sentencas)\n",
    "            sentencas = []\n",
    "    arq.close()\n",
    "\n",
    "    #Salvando as sentencas num arquivo\n",
    "    arq = open('../sentencas/' + save_sentencas[i],'w')\n",
    "    for doc in documentos:\n",
    "        for sent in doc: \n",
    "            arq.write(sent + '\\n')\n",
    "        arq.write('\\n')\n",
    "    arq.close()\n",
    "\n",
    "    #Salvando as palavras com suas sentencas nos arquivos\n",
    "    arq = open('../' + save_palavras[i],'w')\n",
    "    for key in sorted(palavras.keys()):\n",
    "        arq.write(key + ' ->> ') #Caracter separador de palavra e sentença\n",
    "        arq.write(str(palavras[key])+'\\n')\n",
    "    arq.close()\n",
    "\n",
    "    #Salvando as sentenças numa variavel\n",
    "    arq = open('../sentencas/' + save_sentencas[i],'r')\n",
    "    texto = arq.read().lower() #Obtem todos os documentos\n",
    "    arq.close()\n",
    "\n",
    "    #Salvando as frequencias nos arquivos\n",
    "    arq = open('../frequencias/' + save_frequencias[i],'w')\n",
    "    for p in sorted(palavras.keys()):\n",
    "        frequencia = 0\n",
    "        '''if(' ' in p):\n",
    "            frequencia = texto.count(p)\n",
    "        else:\n",
    "            frequencia = TextBlob(texto).words.count(p)'''\n",
    "        frequencia = texto.count(p)\n",
    "        arq.write(p + ': ' + str(frequencia) + '\\n')\n",
    "    arq.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
